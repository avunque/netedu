{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec184c6",
   "metadata": {},
   "source": [
    "\n",
    "# üå≥ √Årboles de Decisi√≥n ‚Äî Versi√≥n Explicativa (v2)  \n",
    "**Curso de An√°lisis de Datos con IA** ¬∑ **Autores:** Doribel Rodr√≠guez y Antonio Vantaggiato\n",
    "\n",
    "**Objetivo pedag√≥gico.** Comprender a fondo c√≥mo funcionan los **√°rboles de decisi√≥n**, entrenar y evaluar modelos con un **dataset cl√°sico (Iris)** y con un **caso aplicado educativo** (aprobaci√≥n de estudiantes), adem√°s de explorar hiperpar√°metros clave para controlar el sobreajuste.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5521d1d4",
   "metadata": {},
   "source": [
    "\n",
    "## üß† Conceptos esenciales\n",
    "\n",
    "- **√Årbol de decisi√≥n (clasificaci√≥n).** Modelo que divide el espacio de caracter√≠sticas mediante reglas **if/else** para predecir una clase.  \n",
    "- **Nodos y hojas.** Cada **nodo** aplica una condici√≥n (por ejemplo, `petal_length ‚â§ 2.4`); cada **hoja** asigna una clase.  \n",
    "- **Criterios de partici√≥n.**  \n",
    "  - **Gini**: mide impureza de una partici√≥n.  \n",
    "  - **Entrop√≠a**: mide desorden; ambas buscan **m√°xima pureza** de las hojas.  \n",
    "- **Sobreajuste.** √Årboles muy profundos memorizan el conjunto de entrenamiento: baja generalizaci√≥n.  \n",
    "- **Control de complejidad.** `max_depth`, `min_samples_leaf`, `min_samples_split`, **poda de coste-complejidad**.\n",
    "\n",
    "> Intuici√≥n: un buen √°rbol encuentra **cortes simples** que separan clases con la **menor impureza** posible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc013e",
   "metadata": {},
   "source": [
    "## 1) Preparaci√≥n del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn import datasets\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a6822",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Dataset cl√°sico: **Iris** (clasificaci√≥n de flores)\n",
    "\n",
    "Este dataset contiene 150 flores (3 especies). Usaremos 4 caracter√≠sticas: largo/ancho de s√©palo y p√©talo.  \n",
    "Evaluaremos un √°rbol b√°sico y analizaremos la matriz de confusi√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c855a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "target_names = iris.target_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "arbol = DecisionTreeClassifier(random_state=42, max_depth=None, criterion=\"gini\")\n",
    "arbol.fit(X_train, y_train)\n",
    "\n",
    "y_pred = arbol.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Exactitud (accuracy) en test: {acc:.3f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=arbol.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names[arbol.classes_])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Matriz de confusi√≥n ‚Äî Iris\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plot_tree(arbol, feature_names=feature_names, class_names=target_names, filled=True, rounded=True)\n",
    "plt.title(\"√Årbol de decisi√≥n ‚Äî Iris\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f1b7da",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1) Explorando la **profundidad m√°xima** (`max_depth`)\n",
    "\n",
    "La profundidad controla la complejidad del √°rbol. Probamos varios valores y observamos la exactitud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec60831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "depths = range(1, 11)\n",
    "scores = []\n",
    "for d in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    cv = cross_val_score(clf, X, y, cv=5)\n",
    "    scores.append(cv.mean())\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(depths, scores, marker=\"o\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy CV (5-fold)\")\n",
    "plt.title(\"Elecci√≥n de profundidad ‚Äî Validaci√≥n cruzada\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b30c57",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Caso aplicado educativo: **Aprobaci√≥n de estudiantes** (dataset simulado realista)\n",
    "\n",
    "Variables (simuladas):  \n",
    "- **asistencia_%**, **horas_estudio**, **participa_clase** (0/1), **tareas_entregadas** (0‚Äì10), **promedio_prev** (0‚Äì100)  \n",
    "- **aprobado** (0/1).\n",
    "\n",
    "Entrenaremos un √°rbol y veremos **importancias de caracter√≠sticas**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572b9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rng = np.random.default_rng(42)\n",
    "n = 180\n",
    "\n",
    "asistencia = rng.normal(80, 10, n).clip(40, 100)\n",
    "horas = rng.normal(6, 2, n).clip(0, 12)\n",
    "participa = rng.integers(0, 2, n)\n",
    "tareas = rng.integers(0, 11, n)\n",
    "prom_prev = rng.normal(75, 12, n).clip(0, 100)\n",
    "\n",
    "# Regla latente para generar aprobado (probabil√≠stica)\n",
    "logit = -6 + 0.04*asistencia + 0.35*horas + 0.6*participa + 0.18*tareas + 0.03*prom_prev\n",
    "prob = 1 / (1 + np.exp(-logit))\n",
    "aprobado = (rng.uniform(0,1,n) < prob).astype(int)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"asistencia_%\": asistencia.round(1),\n",
    "    \"horas_estudio\": horas.round(1),\n",
    "    \"participa_clase\": participa,\n",
    "    \"tareas_entregadas\": tareas,\n",
    "    \"promedio_prev\": prom_prev.round(1),\n",
    "    \"aprobado\": aprobado\n",
    "})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X2 = df[[\"asistencia_%\",\"horas_estudio\",\"participa_clase\",\"tareas_entregadas\",\"promedio_prev\"]]\n",
    "y2 = df[\"aprobado\"]\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.25, random_state=42, stratify=y2)\n",
    "\n",
    "tree2 = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "tree2.fit(X2_train, y2_train)\n",
    "\n",
    "y2_pred = tree2.predict(X2_test)\n",
    "acc2 = accuracy_score(y2_test, y2_pred)\n",
    "print(f\"Exactitud en test (dataset educativo): {acc2:.3f}\")\n",
    "\n",
    "cm2 = confusion_matrix(y2_test, y2_pred, labels=tree2.classes_)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=tree2.classes_)\n",
    "disp2.plot(cmap=\"Greens\")\n",
    "plt.title(\"Matriz de confusi√≥n ‚Äî Estudiantes\")\n",
    "plt.show()\n",
    "\n",
    "# Importancias\n",
    "importancias = pd.Series(tree2.feature_importances_, index=X2.columns).sort_values(ascending=False)\n",
    "print(\"Importancia de caracter√≠sticas:\")\n",
    "display(importancias)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "importancias.plot(kind=\"bar\")\n",
    "plt.title(\"Importancia de caracter√≠sticas ‚Äî √Årbol (estudiantes)\")\n",
    "plt.ylabel(\"Importancia\")\n",
    "plt.grid(axis=\"y\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plot_tree(tree2, feature_names=X2.columns, class_names=[\"No\",\"S√≠\"], filled=True, rounded=True)\n",
    "plt.title(\"√Årbol de decisi√≥n ‚Äî Aprobaci√≥n de estudiantes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9ae08",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Cierre\n",
    "- La **profundidad** del √°rbol y par√°metros como `min_samples_leaf` afectan el equilibrio **sesgo‚Äìvarianza**.  \n",
    "- En el caso educativo, variables como **tareas** y **horas de estudio** suelen tener alta importancia.  \n",
    "- Mant√©n pr√°cticas responsables: valida con datos independientes y revisa sesgos del conjunto.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "arboles_v2.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
